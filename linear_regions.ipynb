{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define a small network with inputs of dimension 5\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 10)\n",
    "        self.rel = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x, **args):\n",
    "        x = self.linear1(x)\n",
    "        x = self.rel(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def reshape_jacobian(jac):\n",
    "    # this function is useful for post-processing the output of `torch.autograd.functional.jacobian`. The issue is that if we input\n",
    "    # a tensor of shape (m,n), torch.autograd.functional.jacobian outputs a tensor of shape (m, k, m, n) where k is the dimension of\n",
    "    # the output of the neural network.\n",
    "    dim1 = jac.shape[0]\n",
    "    new_jac = torch.clone(jac[0, :, :, :])\n",
    "    for i in range(0, dim1):\n",
    "        # the (real) jacobian of the j-th output at input i is jac[i, j]\n",
    "        new_jac[:, i, :] = jac[i, :, i, :]\n",
    "    if jac.shape[1] == 1:\n",
    "        # if the output has dimension 1 (as in the case of our model) the kill the first dimension.\n",
    "        new_jac = new_jac[0, :, :]\n",
    "    return new_jac\n",
    "\n",
    "\n",
    "def get_jacobian(model, x, scale):\n",
    "    # this corresponds to the original way of computing the gradient\n",
    "    x_input = autograd.Variable(x, requires_grad=True)\n",
    "    output = model.forward(x_input)\n",
    "    grad = (\n",
    "        torch.round(\n",
    "            scale\n",
    "            * autograd.grad(output[:, 0].sum(), x_input, retain_graph=True)[0].data\n",
    "        )\n",
    "        / scale\n",
    "    )\n",
    "    return grad\n",
    "\n",
    "\n",
    "def get_region(model, x, scale=1e8, use_torch_jacobian=False):\n",
    "    # This function returns a list giving the region corresponding to each input in x, and the total number of regions.\n",
    "\n",
    "    # compute jacobian at each point in input tensor x\n",
    "    if use_torch_jacobian:\n",
    "        grad = torch.autograd.functional.jacobian(model.forward, x, vectorize=True)\n",
    "        grad = reshape_jacobian(grad)\n",
    "    else:\n",
    "        grad = get_jacobian(model, x, scale)\n",
    "\n",
    "    # remove repetitions from grad (along dimension 0, i.e. repetitions of jacobians)\n",
    "    region_grad = torch.unique(grad, dim=0)\n",
    "    # initialise 1D tensor that will contain the index of the region corresponding to each point in `x`\n",
    "    region = torch.zeros(x.shape[0], dtype=int)\n",
    "\n",
    "    # now we iterate through all the jacobians attained in region_grad. At each step we will compute the indices of the\n",
    "    # inputs in x which attained a specific jacobian and update the `region` tensor accordingly.\n",
    "    for index, r in enumerate(region_grad):\n",
    "        # write the gradient as a tensor of shape (m, 2) where m is the number of points\n",
    "        reshaped_grad = grad.reshape(x.shape[0], -1)\n",
    "        # compute the 2D tensor whose ij-th entry is True if reshaped_grad[i,j] = r[j]\n",
    "        test_eq = torch.eq(reshaped_grad, r)\n",
    "        # take the sum over columns to get the 1D tensor whose i-th entry is 2 precisely when reshaped_grad[i,:] = r\n",
    "        test_eq = torch.sum(test_eq, axis=1)\n",
    "        # get the indices where this equality holds\n",
    "        l = torch.where(test_eq == 2)\n",
    "        # set the entry of region at each one of these indices to be `index`\n",
    "        region[l] = index\n",
    "    return (region, region_grad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of regions is  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivbhatia/AllFiles/dev/tropical_nn_python/.venv/lib/python3.10/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3588.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "my_nn = Net()\n",
    "GRID_SIZE = 100\n",
    "x = torch.linspace(-1, 1, GRID_SIZE)\n",
    "y = torch.linspace(-1, 1, GRID_SIZE)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "# write the meshgrid as a tensor of shape (GRID_SIZE**2, 2)\n",
    "XY = torch.stack((X, Y), axis=2).reshape(-1, 2)\n",
    "R, n_reg = get_region(my_nn, XY)\n",
    "\n",
    "print(\"Total number of regions is \", n_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial method took  0.01823115348815918  seconds\n",
      "Autograd Jacobian method took 2.6742889881134033  seconds\n"
     ]
    }
   ],
   "source": [
    "## autograd.jacobian vs the original method:\n",
    "\n",
    "start = time.time()\n",
    "R, n_reg = get_region(my_nn, XY)\n",
    "mid = time.time()\n",
    "R, n_reg = get_region(my_nn, XY, use_torch_jacobian=True)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Initial method took \", mid - start, \" seconds\")\n",
    "print(\"Autograd Jacobian method took\", end - mid, \" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
